\chapter{Implementation}
\label{sec:implementation}

	% •	Realize the design: give technical detail on what was actually implemented
	% •	Be more practical and objective (e.g., code structure, wiring, services)
	% •	Report what worked, what didn’t (e.g., speed scaling issue), and why
	% •	Clarify how data were collected, labeled, and used in the twin
	% •	Include figures, screenshots, command snippets, JSON logs if relevant
\section{System Architecture}
% Describe physical setup and components
The complete architecture of the Cotton Candy Digital Twin system, including sensor integration, edge computing via the Raspberry Pi, and data forwarding to the lab server, is illustrated in Figure~\ref{fig:ccdt-architecture}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/Architecture of the CC DT.png}
    \caption{Full system architecture of the Cotton Candy Digital Twin, showing sensor integration, Raspberry Pi services, SSH-tunneled data flow, and cloud-based processing.}
    \label{fig:ccdt-architecture}
\end{figure}

\begin{itemize}
  \item Cotton Candy Machine (RCZK-1030-W)
  \item UR5e Robot Arm + Gripper
  \item Custom 3D-printed parts (cite CAD)
  \item Overall process overview (from sugar fill to cotton candy placement)
\end{itemize}

\section{Sensor Integration}
% Describe types, placement, purpose
\begin{itemize}
  \item Temperature \& Humidity Sensors (HDC3021, IR)
  \item Multiplexer setup (TCA9548A)
  \item Edge device: Orange Pi Zero 2W
  \item MQTT-based data forwarding
\end{itemize}

\section{Process Orchestration via CPEE}
% How the robot and machine steps are modelled
\begin{itemize}
  \item Overview of CPEE workflows (Model Screenshot)
  \item Services defined for robot actions (e.g., fill spoon, rotate stick)
  \item Integration with HTTP and MQTT
\end{itemize}

\subsection{Limitations in Speed Parameterization}
% Your paragraph about robot speed control
% Why speed was excluded, how UR controller scaled it down
\section{Data Collection Pipeline}
% Where you log data and what gets captured
\begin{itemize}
  \item Environment registry service
  \item Process instance UUID mapping
  \item Storage format (e.g., YAML, JSON, CSV, MQTT logs)
\end{itemize}

\section{Digital Twin Model Construction}
% ML model used, how trained
\begin{itemize}
  \item Feature selection and preprocessing
  \item Target variables
  \item Model used (e.g., Random Forest)
  \item Tools \& libraries
\end{itemize}


\section{Starting Automata v0}
TODO What we learned when we created the automata and the simple function that we are gonna use for data collection.
\subsection{Its Parameters/Features}

%Make this small

\subsection{Sugar Amount}\label{subsec:sugar-amount}
To calibrate the sugar dispensing system, we measured the mass of sugar released over dispensing durations of 0.5s, 1s, 1.5s and 2s, with ten trials conducted at each setting (noting that 2 s slightly overflowed the spoon). The resulting median amounts dispensed were 8.50g, 12.63g, and 16.64g, 20.58g, respectively. These findings confirmed a roughly linear relationship between dispensing duration and sugar quantity. For all subsequent trials and modeling, we standardized the input to 1s of sugar dispensing (12.63g).

\subsection{Waiting Time}
Waiting time refers to how long the robot arm has to wait until sugar starts coming out of the head. The cold-start time was a variable used for the first time (102s) with an environment temperature of ~25°C. 

%dont spoil
In the digital twin implementation, this parameter is not required, as the model incorporates the actual spinner temperature to predict flow onset directly. Variability in waiting time, primarily influenced by the preheating state of the spinner, is analyzed in the final section of this thesis.

\subsection{Cooking Time}
The default cooking time is 105s. This starts once the sugar starts flowing out of the spinner. probably becauase the spinner has reached the desired temperature for more than (10-20 seconds). (TODO: Be sure about this)
The spinning time is always 3.75s.
105/3.75 = 28 spins per run.

\subsection{Cooldown Time}
The cooldown time refers to the period during which the spinner runs without heating in order to cool down after the production run. This step prevents the sugar from burning in subsequent runs. A default cooldown time of 60s was applied. However, we are gonna investigate the effect of increasing or decreasing this value on product quality. The machine manual recommends a cooldown time of 120 s. We adopted the shorter interval of 60 s because, in practice, the operational cycle of refilling sugar and restarting the machine often extends the total interval to approximately 120 s.

\subsection{Cotton Candy Maintenance Iteration}
We record the number of cotton candy production iterations completed since the last maintenance of the machine. Preliminary observations indicate that extended operation without maintenance has a noticeable impact on product quality. The objective is to determine the optimal number of iterations that can be performed before maintenance is required. In this study, we begin with a maximum of 60 iterations. Maintenance involves removing residual sugar and unclogging the spinner using water.



\section{Automata v1 and automatic Quality Score Implementation}
We need the parameters for the quality score
\subsection{Automatic Quality Score}
\subsection{Time-Efficiency}
\subsection{Energy Consumption Measurement}
\label{sec:energy-measurement}

Energy consumption is recorded for each production cycle to enable optimization of process parameters for energy efficiency. These measurements, combined with quality metrics, allow the digital twin system to identify optimal parameter settings that minimize energy usage while preserving product quality.

\subsection{Data Acquisition and Calculation}

Power consumption is measured using a smart plug at 2-second intervals throughout the production process. Total energy consumption is calculated using trapezoidal integration of discrete power measurements:

\[
E = \sum_{i=1}^{n} \frac{P_{i-1} + P_i}{2} \cdot \Delta t_i
\]

where $P_i$ is the power measurement at time $t_i$ and $\Delta t_i$ is the time interval between measurements. The resulting value is converted from Watt-seconds to Watt-hours for practical interpretation of the 5-minute production cycles.

This methodology accounts for energy consumption across all production phases (startup, heating, spinning, and cooldown) and provides the optimization target for energy-efficient cotton candy production.

% \subsection{Power Data Acquisition}
% 
% Power consumption data is collected using a smart plug (Tasmota-compatible device) that measures electrical parameters at 2-second intervals throughout the production process. The plug captures instantaneous power values in Watts, which are logged with precise timestamps in the process execution system (XES) format. Given the short duration of cotton candy production (maximum 5 minutes), this sampling frequency provides sufficient temporal resolution for accurate energy integration.
% 
% \subsection{Energy Calculation Methodology}
% 
% Total energy consumption for each production cycle is calculated using trapezoidal numerical integration of the discrete power measurements over time. This approach accounts for the varying power draw during different phases of the cotton candy making process (heating, spinning, cooling).
% 
% The energy calculation follows the fundamental relationship:
% \[
% E = \int_{t_0}^{t_f} P(t) \, dt
% \]
% 
% where $E$ is the total energy consumed, $P(t)$ is the instantaneous power at time $t$, $t_0$ is the process start time, and $t_f$ is the process end time.
% 
% For discrete measurements taken at intervals $\Delta t = 2$ seconds, the trapezoidal rule approximates this integral as:
% 
% \[
% E \approx \sum_{i=1}^{n} \frac{P_{i-1} + P_i}{2} \cdot \Delta t_i
% \]
% 
% where:
% \begin{itemize}
%     \item $P_i$ is the power measurement at time $t_i$
%     \item $\Delta t_i = t_i - t_{i-1}$ is the time interval between consecutive measurements
%     \item $n$ is the total number of measurement intervals
% \end{itemize}
% 
% The result is expressed in Watt-seconds (Joules), which is then converted to Watt-hours by dividing by 3600:
% 
% \[
% E_{Wh} = \frac{E_{Ws}}{3600}
% \]
% 
% For the typical 5-minute cotton candy production process, Watt-hours provide a more intuitive unit than kilowatt-hours, which would result in very small decimal values.
% 
% \subsection{Process Phase Integration}
% 
% The energy calculation spans the complete production cycle, from process initiation to final cooldown. Key phases include:
% 
% \begin{enumerate}
%     \item \textbf{Startup phase}: Initial power draw as the spinner begins heating
%     \item \textbf{Heating phase}: High power consumption to reach operating temperature
%     \item \textbf{Production phase}: Active spinning and sugar melting with varying power draw
%     \item \textbf{Cooldown phase}: Reduced power consumption during cooling period
% \end{enumerate}
% 
% By integrating power consumption across all phases, the methodology captures the total energy cost of each cotton candy unit, enabling optimization of process parameters for energy efficiency while maintaining product quality.
% 
% \subsection{Data Quality Considerations}
% 
% The trapezoidal integration method assumes linear interpolation between discrete measurement points. While this introduces some approximation error, the 2-second sampling interval is sufficiently fine-grained relative to the thermal and mechanical time constants of the cotton candy machine to provide accurate energy estimates. Additionally, the method handles variable time intervals between measurements, accommodating any minor variations in data logging frequency.

\subsection{Weight Measurement} 

% Stichpunkte:
% - Manually weigh sugar before each run (input)
% - Weigh finished cotton candy on stick
% - Subtract known stick weight to get net cotton candy weight
% - Use same digital scale throughout
% - Needed for yield and fluffiness index

The input mass of sugar for each production run was manually measured using a precision scale with a readability of 0.01 grams. To determine the output mass of the produced cotton candy, the final product (including the stick) was weighed immediately after production using the same scale. The net weight of the cotton candy was then computed by subtracting the known weight of the stick, which was measured prior to the experiment and kept constant across all runs.

Accurate weight measurement was essential for evaluating the amount of produced cotton candy and for computing derived metrics such as the quality and Fluffiness Index. All weight measurements were recorded in grams with a precision of two decimal places.



% TODO: Change Image to a better and smaller one, this is just a placeholder
% \begin{figure}[H]
%         \caption{Comparison between geometric approximation and real cotton candy morphology}
%     \label{fig:volume-comparison}
%     \centering
%         \includegraphics[width=\textwidth]{figures/Schematic-diagram-of-the-oblate-spheroid-and-its-volume-equivalent-sphere.jpg}
%         % \caption{Idealized oblate spheroid}
%         \label{fig:oblate-spheroid}
% \end{figure}
% \begin{figure}[H]
%         \centering
%         \includegraphics[width=\textwidth]{figures/firstCC.jpeg}
%         \caption{Actual cotton candy output}
%         \label{fig:cotton-candy}
% \end{figure}

\subsection{Volume Estimation}
% Stichpunkte:
% - You describe in detail how you estimate volume.
% - You assume the shape is an oblate spheroid (like a UFO).
% - You measure height and width with a ruler.
% - You apply the formula V = 4/3 * pi * a^2 * c
% - You derive a Fluffiness Index = Volume / Weight.

To approximate the spatial characteristics of the cotton candy output, the product was modeled as an oblate spheroid — a flattened ellipsoid shape that approximates the typical morphology observed during production.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Schematic-diagram-of-the-oblate-spheroid-and-its-volume-equivalent-sphere.jpg}
        \caption{Idealized oblate spheroid}
        \label{fig:oblate-spheroid}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/firstCC.jpeg}
        \caption{Actual cotton candy output}
        \label{fig:cotton-candy}
    \end{subfigure}
    \caption{Comparison between geometric approximation and real cotton candy morphology}
    \label{fig:volume-comparison}
\end{figure}

Measurements of the maximum width and height were taken manually using a standard ruler immediately after each production run. Based on these dimensions, the volume \( V \) was estimated using the standard formula for an oblate spheroid:

\[
V = \frac{4}{3} \pi a^2 c
\]

where \( a \) is the equatorial radius (half of the width) and \( c \) is the polar radius (half of the height). Although this approach does not capture fine-grained structural variations, it offers a practical and repeatable method to compare volumetric differences across runs.

To further assess structural quality, a Fluffiness Index was derived as:

\[
\text{Fluffiness Index} = \frac{V}{\text{Weight}}
\]

This index serves as a proxy for the density of the cotton candy, with higher values indicating a lighter, airier structure. The same procedure and tools were applied consistently across all production runs to ensure internal comparability.

\subsection{Limitations in Volume Measurement}

The estimation of cotton candy volume relied on manual measurements of width and height, followed by geometric approximation. While this method provides a reasonable basis for comparative analysis, it is subject to several limitations: (a) the inherently irregular and fragile structure of cotton candy, (b) potential observer bias during manual measurement, and (c) the assumption of a regular geometric shape. As such, the absolute values of estimated volume should be interpreted with caution. However, because the same procedure was applied uniformly across all experimental runs, the relative differences and trends derived from this method remain valid for assessing the effects of the digital twin optimization.


\section{Data Collection \& Analysis}
Cite a little table showing the data we extracted from a process -> then the features and target we are building, etc...

\section{Automata v2}
From what we learned in the Data Analysis from before. We stop looking it as cooldown\_time, ... etc and start looking at the temp of IRO as the top indicator/Changer to improve quality. We tweak the implementation, fragment more the bpm so that the process can cool itself down before starting, because of the importancy and correlation of cooldown\_temp / start\_temp

The new process looks like this 
BPM Process
\subsection{Data Collection, Data Cleaning of the old logs \& Analysis}
\subsection{Creation of our Temp Values Model}
Did we use RandomForest or Decision Tree or Regression?




\section{Automata v3 - Our first Digital Twin}
What is different in the implementation? Basically now we have a service with a model. In the next chapter we are gonna evaluate this final version with the v0 automata.

\subsection{Prescription Part (No time)}



\section{Pressure Functions}
Here I want to briefly show the pressure funcs we get from the scale and our implemented function, and why we decided not to use them (spoiler: to little time)


\section{Product Quality Measurement}
The development of an automated quality assessment system for cotton candy production presented significant challenges due to the inherently complex and variable nature of the product. Initial attempts to quantify cotton candy quality through traditional volumetric measurements proved unfeasible, as the product's form changes dramatically during the spinning process, making consistent volume measurements impractical within our laboratory constraints.

\subsection{Quality Assessment Approach}

Given the limitations of direct physical measurements, we established a ground-truth quality scoring system based on manual evaluation of the first 100 cotton candy samples. Each sample was assessed across three primary dimensions:

\begin{itemize}
    \item \textbf{Weight consistency}: Deviation from target weight parameters
    \item \textbf{Structural integrity}: Evaluation of cotton candy fluffiness and density
    \item \textbf{Overall form quality}: Categorical assessment (1-3 scale: poor, acceptable, good)
\end{itemize}

The manual scoring process was conducted systematically to minimize evaluator bias, with scores ranging from 0 to 75 points. This approach provided a consistent baseline for developing an automated quality prediction system.

\subsection{Algorithmic Quality Prediction}

To automate quality assessment, we used machine learning to predict quality scores from sensor measurements. The system uses three types of input data:

\begin{itemize}
    \item \texttt{touch\_pos1-3}: Contact positions when the robotic arm touches the cotton candy to measure its size at different heights
    \item \texttt{max\_pos1-3}: Pressure readings when moving the cotton candy down 5cm and back up, indicating structural strength
    \item \texttt{cc\_weight}: Final weight of cotton candy (without stick) from 12.65g sugar input
\end{itemize}

We developed a linear regression model with custom features based on our understanding of cotton candy quality. This process involved several key steps and discoveries:

\textbf{Understanding the Data:} Each cotton candy sample gives us seven measurements - three touch positions, three pressure readings, and one weight. The touch positions tell us how big the cotton candy is at different heights. When the robotic arm can touch the cotton candy close to the stick, it means the cotton candy is fluffy and well-formed. When it has to reach far out, the cotton candy is either too dense or poorly shaped.

\textbf{Smart Features:} We created mathematical formulas that capture what makes good cotton candy. Instead of just using raw measurements, we built features that understand cotton candy physics:
\begin{itemize}
    \item \textbf{Weight optimality:} We learned that 9--12 grams is the sweet spot for high-quality cotton candy. Too light means not enough sugar stuck to form proper structure, while too heavy indicates the presence of lumps from previous production runs, which creates an undesirable texture. Weights of 7--9 grams produce normal quality but receive lower scores, while anything below 7 grams indicates poor cotton candy formation.
    \item \textbf{Touch quality:} The touch position measurements work inversely---smaller distances (closer to the stick) indicate better structure and fluffiness. When the sensor reads 11, it means the robotic arm didn't make contact at all, representing the worst possible structure. The optimal range appears to be between 3--6, though the exact sweet spot within this range required empirical determination through our dataset. For the height (\texttt{touch\_pos2}), 6 means no contact at all.
    \item \textbf{Pressure patterns:} The way cotton candy resists being pushed down reveals its internal structure. Too little pressure (below 20 grams) indicates the cotton candy is overly fluffy with poor cohesion, while too much pressure (above 30 grams) suggests crystallization and density issues that reduce quality. The optimal pressure range of 20--30 grams indicates proper sugar fiber formation and structural integrity.
    \todo{cite the research that we did up that proves this}
\end{itemize}

\textbf{The First Problem - Training Bias:} Our initial approach had a major flaw. We only used data from successful production runs (iterations 56 and above) because we thought this would give us a "clean" dataset. This was a mistake. The algorithm learned to recognize good cotton candy but had never seen truly bad cotton candy during training. When we tested it on early production attempts, it consistently gave scores that were 30 points too high - it simply didn't know what failure looked like.

\textbf{The Solution - Complete Dataset Training:} We retrained the model using all 72 samples, including the early failed attempts where we were still learning how to operate the machine. This gave the algorithm experience with the full quality spectrum, from complete failures to perfect cotton candy. The improvement was dramatic - the bias problem disappeared.

\textbf{Why We Used All Data:} Unlike typical machine learning projects where you split data into training and testing sets, we used our complete dataset for training. This decision follows best practices for small dataset scenarios \cite{Zaki2020}. Since our goal was to build a production tool rather than prove the algorithm works on unseen machines, using all available data gave us the best possible model for our specific setup.

\textbf{Feature Selection Process:} We systematically tested which measurements actually helped predict quality. Some obvious candidates failed completely - for example, height measurements were inconsistent because cotton candy changes shape so easily. We kept only the features that showed reliable correlation with human quality judgments across all our samples.

\subsection{Validation Results}

The final algorithm achieved strong correlation with manual assessments (r = 0.853, MAE = 7.83 points). The correlation coefficient shows the algorithm captures about 73% of quality variation, while the mean absolute error represents roughly 10% deviation on our 0-75 point scale \cite{Zaki2020}.

Figure~\ref{fig:quality_comparison} shows the close match between predicted and actual quality scores across all production runs, validating our approach for automated quality control.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{figures/ground_truth_vs_score3_iterations.png}
    \caption{Comparison of manual quality scores (ground truth) and algorithmic predictions across production iterations. The strong correlation (r = 0.853) validates the automated quality assessment approach.}
    \label{fig:quality_comparison}
\end{figure}

The algorithm successfully captures both the learning progression evident in early iterations and the quality consistency achieved in later production runs, providing a reliable foundation for automated quality control in the digital twin system. This automated quality assessment eliminates the need for manual evaluation while maintaining assessment accuracy, enabling real-time quality monitoring and process optimization.


\section{Feature Engineering for Decision Tree Optimization}
\label{sec:feature-engineering}

To enable effective machine learning optimization, the raw process data was transformed into a structured feature vector suitable for decision tree modeling. This preprocessing involved careful selection and organization of variables to maximize predictive power while minimizing redundancy and computational complexity.

\subsection{Feature Vector Structure}

The final feature vector consists of 28 carefully selected features organized in a logical hierarchy:

\begin{enumerate}
    \item \textbf{Process Parameters (6 features):} Core decision variables including iteration since maintenance, wait time, cook time, cooldown time, and derived timing metrics (duration until handover and total duration)
    \item \textbf{Environmental Baseline (2 features):} External humidity and temperature captured at process initiation to establish ambient conditions
    \item \textbf{Internal Environmental Dynamics (20 features):} Four internal sensors measured across five critical process phases:
    \begin{itemize}
        \item Internal humidity (InH) and temperature (InT) sensors
        \item Infrared ambient temperature (IrA) at the sensor location
        %\item Infrared object temperature (IrO) of the rotating cotton candy machine head, which correlates with the actual internal head temperature (e.g., IrO = 81.55 corresponds to actual internal temperature ≈ 178°C, like we saw before)
    \end{itemize}
\end{enumerate}

\subsection{Redundancy Elimination Strategy}


Analysis of environmental sensor data revealed significant redundancy in external measurements, where external humidity and temperature remained virtually constant throughout the production process (±0.4\% and ±0.1°C variation respectively). To optimize the feature set:

\begin{itemize}
    \item \textbf{External sensors} were reduced from 10 measurements (2 sensors × 5 phases) to 2 baseline measurements, capturing ambient conditions without repetitive data
    \item \textbf{Internal sensors} were retained across all 5 phases, as they exhibited substantial variation (internal humidity: -27\% change, internal temperature: +15°C change, infrared ambient temperature and machine head object temperature: up to +58 units variation)
\end{itemize}

This optimization reduced the environmental feature space from 30 to 22 features while preserving all meaningful environmental dynamics, resulting in a 22\% reduction in feature dimensionality without information loss.

\subsection{Process Phase Identification}

Five critical process phases were identified for environmental monitoring:

\begin{enumerate}
    \item \textbf{Before turn-on:} Baseline internal conditions prior to machine activation
    \item \textbf{After flow start:} Environmental state during active cotton candy production
    \item \textbf{After flow end:} Conditions immediately following production completion
    \item \textbf{After weigh start:} Environmental state at cooling phase initiation
    \item \textbf{End:} Final environmental conditions post-cooling
\end{enumerate}

This temporal sampling strategy captures the complete thermal and humidity evolution during cotton candy production, enabling the decision tree to learn correlations between environmental conditions and process outcomes.

\section{Parameter Optimization Results}
\label{sec:parameter-optimization}
Through comprehensive analysis of the collected dataset using machine learning techniques (Random Forest, Extra Trees, and Gradient Boosting), we identified optimal parameter bounds for the three critical control variables. The analysis revealed that environmental humidity sensors (particularly \texttt{before\_turn\_on\_env\_InH} and during \texttt{flow\_env\_InH}) are the most important quality predictors, followed by timing parameters.

\subsection{Optimized Parameter Bounds}

Based on the decision tree analysis of high-quality samples (quality score $\geq$ 70), the following parameter bounds were established:

\begin{itemize}
    \item \textbf{Wait Time:} 34--54 seconds (optimal: 44 seconds)
    \begin{itemize}
        \item Significantly reduced from initial default of 102 seconds
        \item Reduces energy consumption while maintaining quality
        \item Accounts for pre-heated machine state in continuous production
    \end{itemize}
    
    \item \textbf{Cook Time:} 66--77 seconds (optimal: 71 seconds)
    \begin{itemize}
        \item Reduced from initial default of 105 seconds
        \item Balances sugar caramelization with energy efficiency
        \item Prevents overcooking that leads to crystallization
    \end{itemize}
    
    \item \textbf{Cooldown Time:} 54--57 seconds (optimal: 55 seconds)
    \begin{itemize}
        \item Slightly reduced from default 60 seconds
        \item Prevents residual sugar burning in subsequent runs
        \item Optimizes cycle time for batch production
    \end{itemize}
\end{itemize}

\subsection{Environmental Adaptation Strategy}

For challenging environmental conditions (low humidity or temperature), the following parameter adjustments are recommended:

\begin{itemize}
    \item \textbf{Low Before Turn-On Conditions} (humidity $\leq$ 33\% or temperature $\leq$ 26\textdegree C):
    \begin{itemize}
        \item Wait Time: Increase to 45--50 seconds
        \item Cook Time: Increase to 72--75 seconds  
        \item Cooldown Time: Maintain 55--57 seconds
    \end{itemize}
\end{itemize}

These bounds represent a 32\% reduction in total cycle time compared to initial parameters while maintaining quality scores above 70 points.

\subsection{Production Phase Temperature Control}

Analysis of the machine head temperature during active cotton candy production revealed critical temperature thresholds for quality optimization. The infrared object sensor (\texttt{after\_flow\_start\_env\_IrO}) monitoring the spinning head temperature during sugar flow provides real-time feedback for production quality control.

\subsubsection{Optimal Temperature Bounds}

Machine learning analysis identified a narrow temperature window that produces consistently high-quality cotton candy:

\begin{itemize}
    \item \textbf{Target Range:} 74.5--76.0\textdegree C (optimal production temperature)
    \begin{itemize}
        \item Produces quality scores of 70+ points
    \item 42.1\% success rate for high-quality samples ($\geq$65 points)
        \item Average quality score: 68.2 points in this range
    \end{itemize}
    
    \item \textbf{Acceptable Range:} 74.0--76.5\textdegree C (good quality zone)
    \begin{itemize}
        \item Maintains acceptable quality with minor variations
        \item Provides operational flexibility for temperature fluctuations
    \end{itemize}
    
    \item \textbf{Critical Thresholds:} $<$ 70\textdegree C or $>$ 77\textdegree C (intervention required)
    \begin{itemize}
        \item Below 70°C: Poor quality (average 33.1 points, 0\% high-quality rate)
        \item Above 76°C: Risk of overheating and sugar crystallization
    \end{itemize}
\end{itemize}

\subsubsection{Temperature Progression Analysis}

The analysis revealed optimal temperature progression patterns from machine startup to active production:

\begin{itemize}
    \item \textbf{Pre-production temperature:} 55--60\textdegree C (\texttt{before\_turn\_on\_env\_IrO})
    \item \textbf{Production temperature:} 74.5--76.0\textdegree C (\texttt{after\_flow\_start\_env\_IrO})
    \item \textbf{Temperature increase:} +15--19\textdegree C during transition to production
\end{itemize}

This temperature progression ensures proper sugar melting without overcooking, achieving optimal cotton candy formation.

\subsubsection{Real-time Temperature Control Strategy}

For implementation in the next 100 iterations, the following temperature control logic will be applied:

\begin{table}[htbp]
    \centering
    \caption{Production phase temperature control strategy}
    \label{tab:temp-control}
    \begin{tabular}{|l|l|l|l|}
        \hline
        \textbf{Temperature Range} & \textbf{Action} & \textbf{Quality Level} & \textbf{Strategy} \\
        \hline
    $<$ 70\textdegree C & Increase heating & Poor & More heating \\
    70--74\textdegree C & Monitor closely & Moderate & Standard \\
    	extbf{74--76\textdegree C} & \textbf{Maintain} & \textbf{Excellent} & \textbf{OPTIMAL} \\
        > 76°C & Reduce heat & Risk zone & Cool down \\
        \hline
    \end{tabular}
\end{table}

This real-time temperature monitoring enables dynamic process adjustment to maintain optimal production conditions throughout each cotton candy cycle.

\subsection{Implementation for Next 100 Iterations}

The optimized parameter bounds will be implemented in the next 100 production iterations to validate their effectiveness in practice. The digital twin system will:

\begin{enumerate}
    \item Apply the parameter bounds as constraints in the decision tree optimization
    \item Monitor quality outcomes to confirm the 70+ quality score target is maintained
    \item Track energy consumption reduction compared to baseline parameters
    \item Collect additional environmental sensor data to refine the adaptation strategy
    \item Document any edge cases requiring parameter adjustments beyond the established bounds
\end{enumerate}

This implementation phase will serve as final validation that the machine learning-derived parameter optimization translates to consistent quality improvements in real-world production scenarios.
