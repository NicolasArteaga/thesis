\chapter{Discussion}
\label{sec:discussion}

\section{Measurement Limitations}
% Stichpunkte:
% - Volume measurements were approximate.
% - Shape irregularities and human error may affect accuracy.
% - Nevertheless, same method = reliable trends.
% - Future work could use more advanced shape capture.

While the estimation of product volume provided useful insights into structural quality, it is subject to several limitations. The irregular shape and delicate structure of cotton candy introduce measurement uncertainty, especially when relying on manual tools such as a ruler. Furthermore, the assumption of an ideal oblate spheroid shape simplifies the actual morphology, which may vary significantly across runs.

Despite these limitations, the same procedure was applied consistently throughout the experiments, ensuring the validity of comparative trends. For future work, more precise volume estimation techniques such as 3D scanning or photogrammetric analysis could be explored to capture the complex geometry of the product more accurately.

\section*{Answering Research Question 4}
\textbf{How transferable and generalizable are the methods and insights derived from the Cotton Candy Automata digital twin to other process environments?}

Let us recall Research Question 4 (\ref{sec:intro:rq}), which investigates whether the bottom-up methodology developed in this thesis can be applied beyond the cotton candy case. While the empirical focus is limited to a single robotic system, the approach is designed at an abstraction level (defined in terms of inputs, controls, states, outputs, and constraints) that allows for transferability to other thermo-transformative processes. We provide a conceptual mapping to popcorn production as a demonstration case.

\paragraph{Conceptual Mapping.}
In line with the Digital Twins of Business Processes: A Research Manifesto \cite{FORNARI2025101477}, digital twins operate at the intersection of the \textit{Physical Space} and the \textit{Digital Space}. The physical space includes both the \textit{system} (machines, materials, actuators) and the \textit{environment} (contextual conditions such as temperature and humidity), which are captured by sensors and mirrored digitally. The manifesto emphasizes that meaningful twins must incorporate both aspects to provide actionable decision support. This distinction is reflected in the abstraction adopted in this thesis: \textit{Inputs and Controls} correspond to the physical system, while \textbf{States} represent the environment and system conditions that cannot be directly manipulated but exert significant influence on outcomes.

\begin{table}[h!]
  \begin{center}
    \caption{Conceptual mapping of the bottom-up digital twin approach from cotton candy to popcorn.}
    \label{tab:transferability}
    \begin{tabular}{p{3.5cm}|p{5cm}|p{5cm}}
      \textbf{Abstraction Layer} & \textbf{Cotton Candy Automata} & \textbf{Popcorn Process} \\
      \hline
      Physical System (Inputs) & Sugar type and amount & Kernel type and amount, oil amount \\
      Physical System (Controls) & Heater temperature, spinning duration, cooling temp & Heater temperature, oil preheating, shaking/venting pattern \\
      Environment (States) & Inner pot temperature, ambient temperature and humidity & Pot/oil temperature, ambient temperature, steam release, acoustic pop rate \\
      Outputs (KPIs) & Cotton candy mass, product quality (texture, stickiness), energy usage, total time & Popped mass, unpopped kernels, burnt kernels, energy usage, total time \\
      Constraints & Safety temperature limits, motor stability & Oil smoke point, fire risk, safety temperature limits \\
    \end{tabular}
  \end{center}
  \floatfoot{The table distinguishes between the \textit{physical system} (inputs and controls) 
  and the \textit{environment} (states), following the perspective of the \cite[Digital Twins of Business Processes: A Research Manifesto]{FORNARI2025101477}}.
%---  \todo{Notizen machen wenig Sinn}
\end{table} 

    
\paragraph{Application to Popcorn.}
To demonstrate transferability, the Cotton Candy Automata methodology was conceptually mapped to another thermo-transformative process: popcorn production. Both processes rely on heat-induced material transformation, where quality and efficiency depend on precise control of time, temperature, and environmental conditions. In cotton candy, the digital twin tracks sugar input, heating duration and temperature to optimize yield, energy use, and product texture. In popcorn, analogous parameters can be identified: kernel mass and oil quantity as inputs, heater duty cycle and venting pattern as controls, and acoustic pop rate and steam release as environmental states. Outputs such as unpopped kernels, burnt kernels, and energy per gram popped are directly comparable to the quality, energy, and throughput metrics in cotton candy.

\paragraph{Answer to RQ4.}
The comparison demonstrates that the bottom-up digital twin approach is not locked to a single system but generalizable to structurally similar processes. By abstracting system-specific details into layers of \textit{Inputs, Controls, States, Outputs, and Constraints}, the methodology provides a template that can be applied across domains. While the empirical implementation in this thesis focuses on cotton candy, the conceptual extension to popcorn shows that the same modeling and optimization principles can be applied with minimal methodological adjustments. This aligns with the manifestoâ€™s claim that digital twins must integrate both physical and environmental factors to support prescriptive decision-making \parencite{FORNARI2025101477}. Therefore, the results of this thesis have broader relevance for other small-scale thermo-transformative processes (e.g., roasting, baking, drying), indicating that the developed approach has the potential to inform digital twin design beyond the specific case of cotton candy.

\section{Reflections and Lessons Learned}
\label{sec:discussion:lessons}

\paragraph{A Digital Twin Model without Sensors:}
In hindsight, I would have begun by training a digital twin model relying solely on cook time, wait time, and cooldown time, excluding sensor data. This approach would have enabled a quick baseline without the delay of configuring and testing sensors. Initial quality scores could have been manually classified into three categories (bad, okay, and good) to identify basic patterns. Although subjective, this early data might have reduced the number of batches required for fine-tuning once sensor data became available and before the quality scoring was automated. 

However, it remains unclear whether this strategy would have accelerated model development. Since the process proved complex enough, reliable sensor data for temperature measurements was indispensable. Moreover, thorough evaluation still required multiple production cycles, each taking approximately ten minutes, limiting the extent to which this shortcut could have reduced overall effort.


\paragraph{Reflections on CPEE Expressiveness:}
Extracting features from the CPEE model logs was challenging, as they often contained more than 70,000 lines and thousands of events. Each model update required a new extraction script that had to be implemented and tested, making the process cumbersome. In retrospect, a more efficient solution would have been to add a single script event at the end of each process execution that stored all relevant data elements in the log (e.g., in the third-to-last event). This would have allowed the extraction code to access the required values directly, rather than iterating through the entire log. Likewise, storing derived values such as time differences within data elements would have eliminated the need for additional post-hoc calculations.

\section{A True Prescriptive Digital Twin}
The implementation developed in this thesis represents a step toward, but does not yet achieve, a fully prescriptive digital twin. In its current state, the system provides a functional model of the production process; however, it does not autonomously update and refine itself at regular intervals as new data becomes available. In other words, the digital twin is not yet self-actualizing and does not operate continuously in the background without human intervention.

The prototype includes a service layer that processes each production log by passing it to the digital twin project, allowing historical data to be backtracked and analyzed. Extending this into a complete, continuously updating system would have required at least an additional month of development and testing, as validation of such functionality is particularly time-intensive. Furthermore, we assessed that such an extension would have offered only limited short-term benefits. Continuous operation of the digital twin in tandem with the physical system still requires a human operator to remain in the laboratory for safety supervision and to ensure correct synchronization between the digital model and the physical outcomes (e.g., verifying the exact moments when cotton candy begins and ends production). Each production cycle takes approximately ten minutes, excluding setup, cleaning, and maintenance, which further constrains the pace of testing and iteration. As a result, while our implementation demonstrates the feasibility of prescriptive digital twin concepts, it falls short of achieving full autonomy within the scope of this thesis.


\section{Integrating Live Process Data into the Digital Twin}
As part of the system setup, we implemented a lightweight registry service ('cc\_registry') running on the Raspberry Pi. The service accepts POST requests from the CPEE whenever a new process instance is started, storing its UUID together with contextual information such as a timestamp and instance URL in a YAML file. A simple Bottle-based web interface then visualizes these records in real time, allowing processes to be tracked, backtracked, and linked directly to their execution logs. This solution ensured that the digital twin could consistently access recent process data without relying on manual configuration or persistent storage overhead. The service was intentionally kept minimalistic, focusing on robustness, retrievability, and transparency of ongoing executions.

While this registry advances the integration of live process data into the digital twin, it remains at the stage of a digital model rather than a fully autonomous prescriptive twin. The system can replay and analyze logs, but it does not yet actualize itself by iteratively retraining or adapting models as new data arrive. This limitation aligns with observations in the literature, where many implementations still lack continuous, bidirectional data flows or real-time adaptation, thereby falling short of Grievesâ€™ original definition of a true digital twin. In our case, further automation would have required significantly more testing effort, which was constrained by the physical setting of the cotton candy automata and the need for continuous human supervision during operation.


\section{Towards a Prescriptive Digital Twin}
The implementation carried out in this thesis demonstrates the core building blocks of a prescriptive digital twin. \todo{I feel like after ending implementation I can make this sentence better} We developed a lightweight registry service and data logging infrastructure that ensured reliable access to process executions, integrated real-time measurements of the automata, and implemented a decision tree-based optimization pipeline for parameter tuning. Together, these components allowed the digital twin to analyze past runs, evaluate parameter impacts, and suggest improved configurations. 

Nevertheless, the system still remains at the stage of a digital model rather than a fully autonomous prescriptive twin. While logs can be replayed and optimization applied retrospectively, the twin does not yet actualize itself by continuously retraining or adapting its models as new data arrive. Completing such a feedback loop would have required several additional weeks of testing, which in this project is particularly time-consuming due to the ten-minute execution time per run and the substantial overhead of cleaning, maintenance, and supervision. Furthermore, human presence remains indispensable, both for safety reasons and for monitoring the discrepancy between machine signals and the actual outcome of cotton candy production. Thus, despite infrastructural progress, the twin remains dependent on external intervention. This limitation mirrors what is observed in recent reviews of digital twin applications, where most implementations remain digital models rather than continuously adapting and prescriptive systems~\cite{KREUZER2024102304}.